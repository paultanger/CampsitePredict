{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "data_dir = 'data/cat_dog_train'\n",
    "validation_data_dir = 'data/cat_dog_val'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(nb_filters, kernel_size, input_shape, pool_size):\n",
    "    model = Sequential()  # model is a linear stack of layers (don't change)\n",
    "\n",
    "    # note: the convolutional layers and dense layers require an activation function\n",
    "    # see https://keras.io/activations/\n",
    "    # and https://en.wikipedia.org/wiki/Activation_function\n",
    "    # options: 'linear', 'sigmoid', 'tanh', 'relu', 'softplus', 'softsign'\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid',\n",
    "                     input_shape=input_shape))  # first conv. layer  KEEP\n",
    "    model.add(Activation('relu'))  # Activation specification necessary for Conv2D and Dense layers\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid'))  # 2nd conv. layer KEEP\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))  # decreases size, helps prevent overfitting\n",
    "    model.add(Dropout(0.5))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Flatten())  # necessary to flatten before going into conventional dense layer  KEEP\n",
    "    print('Model flattened out to ', model.output_shape)\n",
    "\n",
    "    # now start a typical neural network\n",
    "    model.add(Dense(32))  # (only) 32 neurons in this layer, really?   KEEP\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Dropout(0.5))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Dense(nb_classes))  # 10 final nodes (one for each class)  KEEP\n",
    "    model.add(Activation('softmax'))  # softmax at end to pick between classes 0-9 KEEP\n",
    "\n",
    "    # many optimizers available, see https://keras.io/optimizers/#usage-of-optimizers\n",
    "    # suggest you KEEP loss at 'categorical_crossentropy' for this multiclass problem,\n",
    "    # and KEEP metrics at 'accuracy'\n",
    "    # suggest limiting optimizers to one of these: 'adam', 'adadelta', 'sgd'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_size = 2000  # number of training samples used at a time to update the weights\n",
    "    nb_classes = 10    # number of output possibilities: [0 - 9] KEEP\n",
    "    nb_epoch = 10       # number of passes through the entire train dataset before weights \"final\"\n",
    "    img_rows, img_cols = 28, 28   # the size of the MNIST images KEEP\n",
    "    input_shape = (img_rows, img_cols, 1)   # 1 channel image input (grayscale) KEEP\n",
    "    nb_filters = 50    # number of convolutional filters to use\n",
    "    pool_size = (2, 2)  # pooling decreases image size, reduces computation, adds translational invariance\n",
    "    kernel_size = (4, 4)  # convolutional kernel size, slides over image to learn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_hsv[:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_and_featurize_data()\n",
    "model = define_model(nb_filters, kernel_size, input_shape, pool_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during fit process watch train and test error simultaneously\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])  # this is the one we care about"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
